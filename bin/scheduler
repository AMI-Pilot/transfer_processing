#!/usr/bin/env -S pipenv run python3
"""
This is the master process -- it should be a cronjob that is run every minute

It will start all of the worker jobs, verifying that only one copy is running
at any given time.


"""
import _preamble
from ami import Ami
import argparse
import logging
from pathlib import Path
from datetime import datetime
import subprocess
import os
import sys

logger = logging.getLogger()
ami = Ami()
my_config = ami.get_config('scheduler')

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--debug', default=False, action='store_true', help="Turn on debugging")    
    subparsers = parser.add_subparsers(help="Mode", dest="mode")
    p = subparsers.add_parser("schedule", help="Schedule pending tasks")
    p.add_argument("--task", type=str, default=None, help="Run a specific task")
    p = subparsers.add_parser("status", help="Show system status")
    p = subparsers.add_parser("panic", help="Manage the system panic state")
    p.add_argument("state", choices=['on', 'off', 'check'], help="System panic on/off or check")
    p = subparsers.add_parser("hold", help="Put a task on hold")
    p.add_argument("task", help="The task to modify")
    p.add_argument("state", choices=['on', 'off'], help="Hold state")    
    args = parser.parse_args()

    if args.mode is None:
        parser.print_help()
        exit(1)

    if not args.debug:
        logger.setLevel(logging.INFO)
    
    

    if args.mode == "panic":
        panic(args.state)
    elif args.mode == "hold":
        hold(args.task, args.state)
    elif args.mode == "status":
        status()
    elif args.mode == "schedule":
        schedule(args.task, args.debug)



def panic(state):
    panicfile = ami.resolve_path(Path(my_config['lockdir'], 'panic'))    
    logger.warning(f"Setting panic to {state}")
    if state == 'on':
        panicfile.touch()
    elif state == 'off':
        panicfile.unlink(missing_ok=True)


def hold(task, state):
    holdfile = Path(ami.resolve_path(Path(my_config['lockdir'], f"{task}.hold")))
    logger.warning(f"Setting task hold for {task} to {state}")
    if state == "on":        
        holdfile.touch()
    else:
        holdfile.unlink(missing_ok=True)


def schedule(task, debug):
    panicfile = ami.resolve_path(Path(my_config['lockdir'], 'panic'))
    if panicfile.exists():
        logger.debug("In panic mode, not scheduling anything")
        exit(0)

    # get the database just to create it if this is the first run.
    ami.get_db()

    bindir = Path(sys.path[0] + "/../bin")
    if task is None:
        logger.debug("Scheduling tasks")

        for task in my_config['tasks']:
            exefile = Path(bindir, task)        
            if not (exefile.exists() and exefile.is_file() and exefile.stat().st_mode & 0o111):
                logger.debug(f"Task {task} ({exefile!s}) is not executable.  Skipping")
                continue
            
            # dealing with logging is complex when one does double forking and whatnot.  
            # BUT, we can cheat by executing ourselves with a task argument
            lockfile = Path(ami.resolve_path(my_config['lockdir']), task + ".lock")
            if not lockfile.exists():
                cmd = [sys.argv[0]]
                if debug:
                    cmd.append("--debug")
                cmd.extend(['schedule', '--task', task])
                logger.debug(f"Starting background command: {cmd}")                
                subprocess.Popen(cmd, start_new_session=True, stdout=open("/dev/null"), stderr=open("/dev/null"), close_fds=True)
            
        logger.debug("Finished scheduling")
        exit(0)
    else:
        logger.debug(f"Scheduling this specific task: {task}")
        exefile = Path(bindir, task) 

        lockfile = Path(ami.resolve_path(my_config['lockdir']), task + ".lock")
        if lockfile.exists():
            logging.debug(f"Skipping {task}:  lockfile is present")
        else:
            try:
                lockfile.touch()
                p = subprocess.run(str(exefile), 
                                    stdout=subprocess.PIPE, 
                                    stderr=subprocess.STDOUT, 
                                    encoding="utf-8")
                if p.returncode != 0:
                    logger.error(f"Task {task} failed:\n{p.stdout}")
                else:
                    logger.debug(f"Task {task} has completed successfully")
            except Exception as e:
                logger.error(f"Failed when executing task {task}: {e}")
            finally:
                lockfile.unlink(missing_ok=True)                
        




def status():
    lockdir = ami.resolve_path(my_config['lockdir'])
    panicfile = Path(lockdir, "panic")
    print(f"Panic is {'on' if panicfile.exists() else 'off'}")

    print("Task holds:")
    for h in lockdir.glob("*.hold"):
        print(f"  {h.stem} {datetime.fromtimestamp(h.stat().st_mtime)}")

    print("\nTask locks:")
    for l in lockdir.glob("*.lock"):
        print(f"  {l.stem} {datetime.fromtimestamp(l.stat().st_mtime)}")



if __name__ == "__main__":
    main()


